import os
import json
import numpy as np
import onnxruntime as ort
from pathlib import Path

def profile_onnx_model(model_path, input_dict):
    print(f"\\n{'-'*60}")
    print(f"æ­£åœ¨ Profiling {os.path.basename(model_path)}...")
    print(f"{'-'*60}")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ— æ³•æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        return
        
    sess_opts = ort.SessionOptions()
    sess_opts.enable_profiling = True
    
    providers = ['DmlExecutionProvider']
    try:
        session = ort.InferenceSession(model_path, sess_opts, providers=providers)
    except Exception as e:
        print(f"âŒ æ— æ³•è½½å…¥æ¨¡å‹: {e}")
        return

    RUNS = 4
    print(f"å¯åŠ¨é¢„çƒ­å’Œ Profile æ¨ç† (è¿è¡Œ {RUNS} æ¬¡)...")
    for _ in range(RUNS):
        session.run(None, input_dict)
        
    profile_file = session.end_profiling()
    fixed_profile_name = os.path.basename(model_path) + ".profile.json"
    if os.path.exists(fixed_profile_name):
        os.remove(fixed_profile_name)
    os.rename(profile_file, fixed_profile_name)
    profile_file = fixed_profile_name
    print(f"âœ… Profile ç»“æœå·²æå–å¹¶å›ºå®šä¿å­˜è‡³: {profile_file}\\n")
    
    with open(profile_file, "r") as f:
        data = json.load(f)
        
    op_durations = {}
    for entry in sorted(data, key=lambda x: x.get("ts", 0)):
        if "cat" in entry and entry["cat"] == "Node":
            op_name = entry.get("args", {}).get("op_name", entry.get("name", "Unknown"))
            dur = entry.get("dur", 0) # microseconds
            if op_name not in op_durations:
                op_durations[op_name] = []
            op_durations[op_name].append(dur)
            
    filtered_ops = {}
    for op_name, durs in op_durations.items():
        if len(durs) >= RUNS:
            ops_per_run = len(durs) // RUNS
            valid_durs = durs[ops_per_run:] # ä¸¢å¼ƒç¬¬ä¸€éé¢„çƒ­çš„è®°å½•
            filtered_ops[op_name] = sum(valid_durs) / (RUNS - 1) / 1000.0 # è½¬æ¢ä¸º ms
        else:
            filtered_ops[op_name] = sum(durs) / len(durs) / 1000.0
            
    filtered_ops = {k: v for k, v in filtered_ops.items() if v > 0}
    sorted_ops = sorted(filtered_ops.items(), key=lambda x: x[1], reverse=True)
    total_dur = sum(filtered_ops.values())
    
    print(f"ğŸ“Š [ç®—å­è€—æ—¶åˆ†å¸ƒ] {os.path.basename(model_path)}")
    print(f"{'ç®—å­ç±»å‹ (OpType)':<25} | {'æ€»è€—æ—¶ (ms)':<15} | {'å æ¯” (%)':<10}")
    print("-" * 60)
    for op_name, dur_ms in sorted_ops:
        pct = (dur_ms / total_dur) * 100.0 if total_dur > 0 else 0
        if pct < 0.1: continue
        print(f"{op_name:<25} | {dur_ms:<15.3f} | {pct:>5.1f}%")
    print("-" * 60)
    print(f"{'æ€»è®¡ (Total)':<25} | {total_dur:<15.3f} | 100.0%")
    print("(æ³¨: DML åœ¨å¼‚æ­¥æ‰§è¡Œæ—¶ CPU/GPU æ—¶é—´çº¿å­˜åœ¨äº¤å‰ï¼Œç»Ÿè®¡åˆ°çš„é€šå¸¸æ˜¯é©±åŠ¨åˆ†å‘æˆ–åŒæ­¥æ—¶é—´ï¼Œä½†ç™¾åˆ†æ¯”æå…¶ç²¾å‡†åœ°æ­ç¤ºäº†é»‘æ´ç®—å­)")


def main():
    model_dir = os.path.join(Path(__file__).parent.absolute(), "model")
    
    frontend_path = os.path.join(model_dir, "qwen3_asr_encoder_frontend.int4.onnx")
    backend_path = os.path.join(model_dir, "qwen3_asr_encoder_backend.int4.onnx")

    data_type = np.float32
        
    if os.path.exists(frontend_path):
        dummy_frontend = {
            "chunk_mel": np.random.randn(1, 128, 100).astype(data_type)
        }
        profile_onnx_model(frontend_path, dummy_frontend)
        
    if os.path.exists(backend_path):
        hidden_size = 1024
        print(f"\\nğŸ”§ æ£€æµ‹åˆ° Backend éšè—å±‚ç»´åº¦ (hidden_size): {hidden_size}")
        seq_len = 2000
        dummy_backend = {
            "hidden_states": np.random.randn(1, seq_len, hidden_size).astype(data_type),
            "attention_mask": np.zeros((1, 1, seq_len, seq_len), dtype=data_type)
        }
        profile_onnx_model(backend_path, dummy_backend)

if __name__ == '__main__':
    main()
